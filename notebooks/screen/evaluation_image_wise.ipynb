{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 108 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import  namedtuple\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from video699.screen.semantic_segmentation.fastai_detector import *\n",
    "from video699.screen.semantic_segmentation.common import *\n",
    "from video699.screen.semantic_segmentation.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor = [2]\n",
    "frozen_epochs = [4, 7]\n",
    "unfrozen_epochs = [4, 7]\n",
    "base_lower_bound = [5, 7, 10, 15]\n",
    "erosion_dilation_kernel_size = [20, 50, 80, 150]\n",
    "ratio_split_lower_bound = [0.3, 0.4, 0.5, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_factor = [8]\n",
    "# frozen_epochs = [0]\n",
    "# unfrozen_epochs = [0]\n",
    "# base_lower_bound = [15]\n",
    "# erosion_dilation_kernel_size = [20,25]\n",
    "# ratio_split_lower_bound = [0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(product(resize_factor, frozen_epochs, unfrozen_epochs))\n",
    "train_names = ['resize_factor', 'frozen_epochs', 'unfrozen_epochs']\n",
    "\n",
    "post_processing = list(product(base_lower_bound, erosion_dilation_kernel_size, ratio_split_lower_bound))\n",
    "post_processing_names = ['base_lower_bound', 'erosion_dilation_kernel_size', 'ratio_split_lower_bound']\n",
    "\n",
    "all_frames = [frame for video in ALL_VIDEOS for frame in video]\n",
    "\n",
    "detector = FastAIScreenDetector(train=False)\n",
    "actual_detector = AnnotatedSampledVideoScreenDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_by(name, used):\n",
    "    return str(name) in [str(frame.pathname) for frame in used] and 'frame' in str(name)\n",
    "\n",
    "def split_by(name, validation):\n",
    "    return str(name) in [str(frame.pathname) for frame in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(frames, train_names, post_processing_names, default_filtered_by, default_split_by):\n",
    "    def make_splits(frames):\n",
    "        Split = namedtuple('Split', ['train', 'valid'])\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "        splits = {}\n",
    "        for j, split in enumerate(kf.split(frames)):    \n",
    "            train_frames = [frames[index] for index in split[0]]\n",
    "            valid_frames = [frames[index] for index in split[1]]\n",
    "            splits[j] = Split(train=train_frames, valid=valid_frames)\n",
    "        return splits\n",
    "\n",
    "    splits = make_splits(frames)\n",
    "    df_all = pd.DataFrame(columns=train_names + post_processing_names + ['iou', 'wrong_count', 'kfold_split'])\n",
    "\n",
    "    for train_values in tqdm(train):\n",
    "        resize_factor, frozen_epochs, unfrozen_epochs = train_values\n",
    "        CONFIGURATION['resize_factor'] = str(resize_factor)\n",
    "        CONFIGURATION['frozen_epochs'] = str(frozen_epochs)\n",
    "        CONFIGURATION['unfrozen_epochs'] = str(unfrozen_epochs)\n",
    "\n",
    "        for j in splits.keys():\n",
    "            filtered_by = partial(default_filtered_by, used=splits[j].train + splits[j].valid)\n",
    "            split_by = partial(default_split_by, validation=splits[j].valid)\n",
    "\n",
    "            detector = FastAIScreenDetector(filtered_by=filtered_by, valid_func=split_by)\n",
    "            detector.train()\n",
    "            \n",
    "            valid_frames = [frame for frame in all_frames if split_by(frame.pathname)]\n",
    "            actuals = [actual_detector.detect(frame) for frame in valid_frames]\n",
    "            sem_preds = detector.semantic_segmentation_batch(valid_frames)\n",
    "\n",
    "            for post_processing_values in post_processing:    \n",
    "                preds = detector.post_processing_batch(sem_preds, valid_frames, **dict(zip(post_processing_names, post_processing_values)))\n",
    "                wrong_count, ious, _ = evaluate(actuals, preds)\n",
    "                iou_score = np.nanmean(ious)\n",
    "                wrong_count = len(wrong_count)\n",
    "                df_all.loc[len(df_all)] = train_values + post_processing_values + (iou_score, wrong_count, j)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_params(best_params):\n",
    "    converted_params = []\n",
    "    for i, par in enumerate(best_params):\n",
    "        if par.is_integer():\n",
    "            converted_params.append(int(par))\n",
    "        elif isinstance(par, np.int64) or isinstance(par, np.float64):\n",
    "            converted_params.append(par.item())\n",
    "        else:\n",
    "            converted_params.append(par)\n",
    "    best_params = tuple(converted_params)\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture-wise 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      25.00% [1/4 00:30<01:31]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>dice</th>\n",
       "      <th>iou_sem_seg</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.315429</td>\n",
       "      <td>0.069314</td>\n",
       "      <td>0.976123</td>\n",
       "      <td>0.953076</td>\n",
       "      <td>0.913069</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      28.12% [9/32 00:05<00:13 0.2696]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:42<?, ?it/s]\n",
      "0it [00:42, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-7904e53b58c3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;31m# Model selection\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mdf_all\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_selection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother_frames\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpost_processing_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltered_by\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit_by\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mdf_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'wrong_count'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'wrong_count'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mbest_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_all\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_names\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mpost_processing_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'wrong_count'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'iou'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-ddace4983dbc>\u001B[0m in \u001B[0;36mmodel_selection\u001B[0;34m(frames, train_names, post_processing_names, default_filtered_by, default_split_by)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mdetector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFastAIScreenDetector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_by\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfiltered_by\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_func\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msplit_by\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m             \u001B[0mdetector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mvalid_frames\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mframe\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mframe\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mall_frames\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0msplit_by\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpathname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/video699/screen/semantic_segmentation/fastai_detector.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprogressbar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 225\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_one_cycle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfrozen_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrozen_lr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    226\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munfreeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_one_cycle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munfrozen_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munfrozen_lr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/fastai/train.py\u001B[0m in \u001B[0;36mfit_one_cycle\u001B[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001B[0m\n\u001B[1;32m     21\u001B[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001B[1;32m     22\u001B[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0mlearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcyc_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_lr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, epochs, lr, wd, callbacks)\u001B[0m\n\u001B[1;32m    198\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mwd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         \u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mcb\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallback_fns\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlistify\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdefaults\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextra_callback_fns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlistify\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 200\u001B[0;31m         \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    201\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    202\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcreate_opt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mFloats\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwd\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mFloats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m->\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(epochs, learn, callbacks, metrics)\u001B[0m\n\u001B[1;32m     99\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mxb\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0myb\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprogress_bar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpbar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m                 \u001B[0mxb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcb_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcb_handler\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    102\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mcb_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_batch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001B[0m in \u001B[0;36mloss_batch\u001B[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mopt\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mskip_bwd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcb_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_backward_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mskip_bwd\u001B[0m\u001B[0;34m:\u001B[0m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcb_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_backward_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/fastai/callback.py\u001B[0m in \u001B[0;36mon_backward_begin\u001B[0;34m(self, loss)\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mon_backward_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m->\u001B[0m\u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m         \u001B[0;34m\"Handle gradient calculation on `loss`.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 290\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msmoothener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    291\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'last_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'smooth_loss'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msmoothener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msmooth\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'backward_begin'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcall_mets\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "df_best_models = pd.DataFrame(columns=train_names + post_processing_names + ['iou', 'wrong_count'])\n",
    "\n",
    "\n",
    "for i, split in tqdm(enumerate(list(kf.split(all_frames))[:2])):\n",
    "    print(f\"###################### Split No. {i}\")\n",
    "    other_frames = [all_frames[index] for index in split[0]]\n",
    "    test_frames = [all_frames[index] for index in split[1]]\n",
    "    \n",
    "    # Model selection\n",
    "    df_all = model_selection(other_frames, train_names, post_processing_names, filtered_by, split_by)    \n",
    "    df_all['wrong_count'] = df_all['wrong_count'].astype(int)\n",
    "    best_params = df_all.groupby(train_names + post_processing_names).mean().sort_values(by=['wrong_count', 'iou']).iloc[0].name\n",
    "    best_params = convert_params(best_params)\n",
    "    best_params = dict(zip(train_names + post_processing_names, best_params))\n",
    "    test_filtered_by = partial(filtered_by, used=all_frames)\n",
    "    test_split_by = partial(split_by, validation=test_frames)\n",
    "    \n",
    "    \n",
    "    best_detector = FastAIScreenDetector(filtered_by=test_filtered_by, valid_func=test_split_by)\n",
    "    best_detector.train(**best_params)\n",
    "    \n",
    "    test_frames = [frame for frame in all_frames if test_split_by(frame.pathname)]\n",
    "    actuals = [actual_detector.detect(frame) for frame in test_frames]\n",
    "    preds = [best_detector.detect(frame) for frame in test_frames]\n",
    "    \n",
    "    wrong_count, ious, _ = evaluate(actuals, preds)\n",
    "    iou_score = np.nanmean(ious)\n",
    "    wrong_count = len(wrong_count)\n",
    "    df_best_models.loc[len(df_best_models)] = tuple(best_params.values()) + (iou_score, wrong_count)\n",
    "    df_best_models.to_csv('cross_validation_results_image_wise.csv', index=False)\n",
    "    \n",
    "df_best_models.to_csv('cross_validation_results_image_wise.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}