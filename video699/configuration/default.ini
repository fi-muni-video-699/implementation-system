[PDFDocumentPage]
# The maximum size of the LRU cache placed in front of the PDF document page rendering routine.
lru_cache_maxsize = 150
# The OpenCV interpolation flag used when downscaling rendered PDF document pages.
downscale_interpolation = INTER_AREA

[ImageABC]
# The maximum size of the LRU cache placed in front of the image data rescaling routine.
lru_cache_maxsize = 150
# The OpenCV interpolation flag used when rescaling the image data.
rescale_interpolation = INTER_LINEAR

[GEOSConvexQuadrangle]
# The OpenCV interpolation flag used when applying a perspective transformation to a frame image.
rescale_interpolation = INTER_LINEAR

[ScreenABC]
# The maximum size of the LRU cache placed in front of the routine that transforms image data in
# the frame coordinate system to the screen coordinate system.
lru_cache_maxsize = 150

[KerasSiamesePageDetector]
# The width of the Siamese convolutional neural network input layer.
image_width = 381
# The height of the Siamese convolutional neural network input layer.
image_height = 286
# The base weight of a matching image pair in a dataset.
matching_pair_base_weight = 1.0
# The weight of a non-matching image pair in a dataset, where the page image comes from a document
# where no page matches the screen.
distant_nonmatching_pair_weight = 2.0
# The weight of a non-matching image pair in a dataset, where the page image comes from a document
# where some pages match the screen.
close_nonmatching_pair_weight = 5.0
# The maximum number of epochs used to train a Siamese convolutional neural network without a
# validation set.
num_training_epochs = 25
# The minimum weighted accuracy on the training set that is acceptable for a Siamese convolutional
# neural network.
min_training_accuracy = 0.95
# The size of the batches used to train Siamese convolutional neural networks.
training_batch_size = 8
# The size of the batches used to predict features, and class labels from Siamese convolutional
# neural networks.
prediction_batch_size = 80
# The learning rate used to train Siamese convolutional neural networks.
learning_rate = 0.0015
# The width of a convolutional kernel used in a Siamese convolutional neural network.
filter_width = 3
# The height of a convolutional kernel used in a Siamese convolutional neural network.
filter_height = 3
# The number of convnet filters in the top convolutional layers of a Siamese convolutional neural
# network.
num_top_filters = 32
# The number of convnet filters in the bottom convolutional layers of a Siamese convolutional
# neural network.
num_bottom_filters = 64
# The horizontal factor by which the image data is downscaled in the max pooling layer of a Siamese
# convolutional neural network.
maxpool_width = 2
# The vertical factor by which the image data is downscaled in the max pooling layer of a Siamese
# convolutional neural network.
maxpool_height = 2
# The number on units in the fully connected layers at the bottom of a Siamese convolutional
# neural network.
num_dense_units = 64
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The floating point data type used to represent the images fed to Siamese convolutional neural
# networks.
image_dtype = float32
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest value of the sigmoid function that is considered to predict a matching pair in a
# Siamese convolutional neural network. Larger values makes the detector detect pages where
# previously it would detect none.
significance_level = 0.42857142857142855

[FastAIScreenDetector]
# The height of the input image.
image_height = 576
# The width of the input image.
image_width = 720
# The size of the batch used in training. Larger batch_sizes are prone to fitting into memory.
batch_size = 8
# The output size of semantic segmentation is image width and height divided by this factor. That
# output is then linearly resized to the original size.
resize_factor = 2
# The number of epochs to train in frozen mode (training only last conv layer and decoder).
frozen_epochs = 2
# The number of epochs to train in unfrozen mode (whole neural net).
unfrozen_epochs = 7
# The learning rate used in frozen mode (if two values presented, they will be uniformly
# distributed through trained layers).
frozen_lr = 1e-3
# The learning rate used in frozen mode (if two values presented, they will be uniformly
# distributed through trained layers).
unfrozen_lr = 1e-4, 2e-4
# The postprocessing flag - base system for quadrangle approximation from semantic segmentation
base = True
# Discard contours with pixel area percentage lower than base_lower_bound (compared to original image)
base_lower_bound = 7
# Factor is used to discard contours out of bounds:      factor * cv2.arcLength(cnt, True)
# It could by just one value without ", " delimiter, or multiple values that will be processed respectively.
base_factors = 0.1, 0.01
# Postprocessing flag - erosion of original image, than base approximation and than dilation for each retrieved quad.
erosion_dilation = True
# Discard contours with pixel area percentage lower than erosion_dilation_lower_bound (compared to original image)
erosion_dilation_lower_bound = 5
# Factor is used to discard contours out of bounds:      factor * cv2.arcLength(cnt, True)
# It could by just one value without ", " delimiter, or multiple values that will be processed respectively
erosion_dilation_factors = 0.1, 0.01
# Size of the structuring element (kernel) to use for eroding and dilating.
erosion_dilation_kernel_size = 80
# Postprocessing flag - every contour gets a check for ratio between height and width, if it does not corresponds to
# projector screens split it on two halves.
ratio_split = True
# Bound height/width ratio to split vertically.
ratio_split_lower_bound = 0.7
# Model does not fit into GIT, save and load methods make possible to divide model into chunks
# 10000000 B = 10 MB
chunk_size = 50000000

[ImageHashPageDetector]
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The distance metric used for the nearest neighbor retrieval.
distance_metric = hamming
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest distance between the image hash of a screen image and the image hash of a page image
# at which the screen and the page match. Larger values makes the detector detect pages where
# previously it would detect none. Since the dimensionality of the image hashes is 64, the maximum
# possible hamming distance between two image hashes is 64.
max_distance = 22
# The function used to hash images. The available hash functions are average_hash, phash, dhash, and
# whash.
hash_function = phash

[KerasVGG16PageDetector]
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The distance metric used for the nearest neighbor retrieval.
distance_metric = angular
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest distance between the image hash of a screen image and the image hash of a page image
# at which the screen and the page match. Larger values makes the detector detect pages where
# previously it would detect none.
max_distance = 0.8979591836734693
# The size of the batches used to extract last hidden VGG16 layer activations.
batch_size = 80

[MeanSquaredErrorSceneDetector]
# The highest mean squared error between image pixels, in the range [0; 1], before a scene transition
# is detected. Smaller values make the detector detect scene transitions where previously it would
# detect none.
max_mse = 0.2205490400326797
# The width of the downscaled image.
image_width = 320
# The height of the downscaled image.
image_height = 240
