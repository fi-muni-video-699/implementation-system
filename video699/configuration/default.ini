[PDFDocumentPage]
# The maximum size of the LRU cache placed in front of the PDF document page rendering routine.
lru_cache_maxsize = 150
# The OpenCV interpolation flag used when downscaling rendered PDF document pages.
downscale_interpolation = INTER_AREA

[ImageABC]
# The maximum size of the LRU cache placed in front of the image data rescaling routine.
lru_cache_maxsize = 150
# The OpenCV interpolation flag used when rescaling the image data.
rescale_interpolation = INTER_LINEAR

[GEOSConvexQuadrangle]
# The OpenCV interpolation flag used when applying a perspective transformation to a frame image.
rescale_interpolation = INTER_LINEAR

[ScreenABC]
# The maximum size of the LRU cache placed in front of the routine that transforms image data in
# the frame coordinate system to the screen coordinate system.
lru_cache_maxsize = 150

[RollingPearsonPageDetector]
# The number of video frames in the sliding window. A larger window increases sample size and
# improves accuracy.
window_size = 150
# The number of pixels sampled from image data in a single frame of a video. A larger sample size
# improves accuracy.
sample_size = 50000
# The least q-value before we consider the correlation coefficient to be significantly extreme.
# Larger significance level makes the detector detect pages where previously it would detect none.
significance_level = 0.05
# The least Pearson's correlation coefficient that we do not consider extreme. Smaller correlation 
# coefficient makes the detector detect pages where previously it would detect none.
correlation_threshold = 0.5
# Whether we wish to perform feature-based image registration.
use_homography = False
# The maximum size of the LRU cache placed in front of the routine that extracts local image
# features for image registration.
lru_cache_maxsize = 150
# The maximum number of local features extracted from an image for image registration. A larger
# number of local features improves accuracy at the expense of speed and memory usage.
num_features = 500
# The type of the OpenCV local feature descriptor matcher used for image registration.
descriptor_matcher_type = BruteForce
# The percentage of the best descriptor matches that are retained during image registration. A
# larger percentage improves image registration accuracy at the expense of speed.
good_match_percentage = 0.25
# The method used for finding homography between a template and an image during image registration.
find_homography_method = LMEDS
# The OpenCV interpolation flag used when applying a perspective transformation to a page image.
rescale_interpolation = INTER_LINEAR

[LocalFeatureKNNPageDetector]
# The number of video frames in the sliding window. A larger window increases sample size and
# improves accuracy.
window_size = 150
# The maximum size of the LRU cache placed in front of the routine that extracts local image
# features.
lru_cache_maxsize = 150
# The maximum number of local features extracted from an image. A larger number of local features
# improves accuracy at the expense of speed and memory usage.
num_features = 500
# The minimum percentage of local features that needs to be extracted from a projection screen image
# for the detector to detect pages. A smaller minimum percentage of local features makes the
# detector detect pages where previously it would detect none.
min_feature_percentage = 0.2
# The number of nearest local features retrieved during the nearest neighbor retrieval.
num_nearest_features = 5
# The minimum mean percentage of votes a document page must receive before it can be detected in a
# projection screen. A smaller minimum mean percentage of votes makes the detector detect pages
# where previously it would detect none.
min_page_vote_percentage = 0.05
# The distance metric used for the nearest neighbor retrieval.
distance_metric = euclidean
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_features * annoy_n_trees * D,  D is a constant depending on distance_metric.
annoy_search_k = -1

[KerasSiamesePageDetector]
# The width of the Siamese convolutional neural network input layer.
image_width = 381
# The height of the Siamese convolutional neural network input layer.
image_height = 286
# The base weight of a matching image pair in a dataset.
matching_pair_base_weight = 1.0
# The weight of a non-matching image pair in a dataset, where the page image comes from a document
# where no page matches the screen.
distant_nonmatching_pair_weight = 2.0
# The weight of a non-matching image pair in a dataset, where the page image comes from a document
# where some pages match the screen.
close_nonmatching_pair_weight = 5.0
# The maximum number of epochs used to train a Siamese convolutional neural network without a
# validation set.
num_training_epochs = 25
# The minimum weighted accuracy on the training set that is acceptable for a Siamese convolutional
# neural network.
min_training_accuracy = 0.95
# The size of the batches used to train Siamese convolutional neural networks.
training_batch_size = 8
# The size of the batches used to predict features, and class labels from Siamese convolutional
# neural networks.
prediction_batch_size = 80
# The learning rate used to train Siamese convolutional neural networks.
learning_rate = 0.0015
# The width of a convolutional kernel used in a Siamese convolutional neural network.
filter_width = 3
# The height of a convolutional kernel used in a Siamese convolutional neural network.
filter_height = 3
# The number of convnet filters in the top convolutional layers of a Siamese convolutional neural
# network.
num_top_filters = 32
# The number of convnet filters in the bottom convolutional layers of a Siamese convolutional
# neural network.
num_bottom_filters = 64
# The horizontal factor by which the image data is downscaled in the max pooling layer of a Siamese
# convolutional neural network.
maxpool_width = 2
# The vertical factor by which the image data is downscaled in the max pooling layer of a Siamese
# convolutional neural network.
maxpool_height = 2
# The number on units in the fully connected layers at the bottom of a Siamese convolutional
# neural network.
num_dense_units = 64
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The floating point data type used to represent the images fed to Siamese convolutional neural
# networks.
image_dtype = float32
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest value of the sigmoid function that is considered to predict a matching pair in a
# Siamese convolutional neural network. Larger values makes the detector detect pages where
# previously it would detect none.
significance_level = 0.5

[ImageHashPageDetector]
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The distance metric used for the nearest neighbor retrieval.
distance_metric = hamming
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest distance between the image hash of a screen image and the image hash of a page image
# at which the screen and the page match. Larger values makes the detector detect pages where
# previously it would detect none. Since the dimensionality of the image hashes is 256, the maximum
# possible hamming distance between two image hashes is 64.
max_distance = 32
# The function used to hash images. The available hash functions are average_hash, phash, dhash, and
# whash.
hash_function = dhash

[KerasVGG16PageDetector]
# The number of document pages with the nearest deep image features retrieved during the nearest
# neighbor retrieval.
num_nearest_pages = 1
# The distance metric used for the nearest neighbor retrieval.
distance_metric = angular
# The number of trees constructed for the approximate nearest neighbor retrieval. A larger number of
# trees improves accuracy at the expense of memory usage.
annoy_n_trees = 10
# The number of tree nodes inspected during the approximate nearest neighbor retrieval. A larger
# number of tree nodes improves accuracy at the expense of speed. The value of -1 corresponds to
# num_nearest_pages * annoy_n_trees * D,  D is a constant depending on the distance metric.
annoy_search_k = -1
# The highest distance between the image hash of a screen image and the image hash of a page image
# at which the screen and the page match. Larger values makes the detector detect pages where
# previously it would detect none.
max_distance = 0.8979591836734693
# The size of the batches used to extract last hidden VGG16 layer activations.
batch_size = 80

[FrameImageDistanceSceneDetector]
# The highest mean Euclidean distance between image pixels, in the range [0; 1], before a scene
# transition is detected. Smaller values make the detector detect scene transitions where previously
# it would detect none.
max_mean_distance = 0.12336959687424347
