{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure speed for all combinations of page, screen, and scene detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from video699.__main__ import PAGE_DETECTOR_NAMES, SCREEN_DETECTOR_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_speed(page_detector_name, screen_detector_name, scene_detector_name):\n",
    "    start_time = datetime.now()\n",
    "    ! python -m video699 \\\n",
    "        --institution 'fimu' \\\n",
    "        --room 'd2' \\\n",
    "        --camera 'default_2004' \\\n",
    "        --date '2019-11-12T12:00:00+01:00' \\\n",
    "        --documents 'Blockchain-FI-MUNI.pdf' \\\n",
    "        --video 'IA067-D2-20191112.mp4' \\\n",
    "        --output '/dev/null' \\\n",
    "        --page-detector '{page_detector_name}' \\\n",
    "        --screen-detector '{screen_detector_name}' \\\n",
    "        --scene-detector '{scene_detector_name}' \\\n",
    "        1>/dev/null 2>&1\n",
    "    finish_time = datetime.now()\n",
    "    conversion_duration = (finish_time - start_time).total_seconds()\n",
    "    video_duration = 4545.066667\n",
    "    conversion_speed = video_duration / conversion_duration\n",
    "    return conversion_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_speeds(scene_detector_name):\n",
    "    conversion_speeds = dict()\n",
    "    for page_detector_name in PAGE_DETECTOR_NAMES:\n",
    "        conversion_speeds[page_detector_name] = dict()\n",
    "        for screen_detector_name in SCREEN_DETECTOR_NAMES:\n",
    "            parameters = (page_detector_name, screen_detector_name, scene_detector_name)\n",
    "            conversion_speeds[page_detector_name][screen_detector_name] = conversion_speed(*parameters)\n",
    "    df = pd.DataFrame.from_dict(conversion_speeds)\n",
    "    df = df.append(pd.Series(df.sum(), name='total'))\n",
    "    df = df.T.append(pd.Series(df.T.sum(), name='total')).T\n",
    "    df = df.sort_values(by='total', axis=0, ascending=False)\n",
    "    df = df.sort_values(by='total', axis=1, ascending=False)\n",
    "    df = df.drop('total', axis=0)\n",
    "    df = df.drop('total', axis=1)\n",
    "    df = df.style.background_gradient(cmap='RdYlGn', axis=None)\n",
    "    df = df.format('{:.2f}×')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video conversion speeds for all combinations of screen detectors (rows) and page detectors (columns) using no scene detector. The test was performed with a quad-core Intel Core i7-8550U CPU and a NVIDIA Tesla T4 GPU. Speeds are relative to video duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col1 {\n",
       "            background-color:  #fff2aa;\n",
       "            color:  #000000;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col2 {\n",
       "            background-color:  #f57547;\n",
       "            color:  #000000;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col3 {\n",
       "            background-color:  #ce2827;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col0 {\n",
       "            background-color:  #a90426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col1 {\n",
       "            background-color:  #a90426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col2 {\n",
       "            background-color:  #a70226;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col3 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >annotated</th>        <th class=\"col_heading level0 col1\" >imagehash</th>        <th class=\"col_heading level0 col2\" >siamese</th>        <th class=\"col_heading level0 col3\" >vgg16</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734flevel0_row0\" class=\"row_heading level0 row0\" >annotated</th>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col0\" class=\"data row0 col0\" >21.70×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col1\" class=\"data row0 col1\" >10.31×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col2\" class=\"data row0 col2\" >5.16×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow0_col3\" class=\"data row0 col3\" >2.51×</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734flevel0_row1\" class=\"row_heading level0 row1\" >fastai</th>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col0\" class=\"data row1 col0\" >0.94×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col1\" class=\"data row1 col1\" >0.89×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col2\" class=\"data row1 col2\" >0.80×</td>\n",
       "                        <td id=\"T_bc829720_9ad7_11ea_bc9e_525400d3734frow1_col3\" class=\"data row1 col3\" >0.71×</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8686f667b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversion_speeds(scene_detector_name='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video conversion speeds for all combinations of screen detectors (rows) and page detectors (columns) using the `FrameImageDistanceSceneDetector` scene detector. The test was performed with a quad-core Intel Core i7-8550U CPU and a NVIDIA Tesla T4 GPU. Speeds are relative to video duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col1 {\n",
       "            background-color:  #9dd569;\n",
       "            color:  #000000;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col2 {\n",
       "            background-color:  #ecf7a6;\n",
       "            color:  #000000;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col3 {\n",
       "            background-color:  #f7844e;\n",
       "            color:  #000000;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col0 {\n",
       "            background-color:  #b71126;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col1 {\n",
       "            background-color:  #b50f26;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col2 {\n",
       "            background-color:  #ad0826;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col3 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >annotated</th>        <th class=\"col_heading level0 col1\" >imagehash</th>        <th class=\"col_heading level0 col2\" >siamese</th>        <th class=\"col_heading level0 col3\" >vgg16</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734flevel0_row0\" class=\"row_heading level0 row0\" >annotated</th>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col0\" class=\"data row0 col0\" >6.31×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col1\" class=\"data row0 col1\" >4.69×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col2\" class=\"data row0 col2\" >3.76×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow0_col3\" class=\"data row0 col3\" >1.99×</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734flevel0_row1\" class=\"row_heading level0 row1\" >fastai</th>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col0\" class=\"data row1 col0\" >0.87×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col1\" class=\"data row1 col1\" >0.83×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col2\" class=\"data row1 col2\" >0.76×</td>\n",
       "                        <td id=\"T_72d375b8_9a8c_11ea_bc9e_525400d3734frow1_col3\" class=\"data row1 col3\" >0.65×</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f86846766d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversion_speeds(scene_detector_name='distance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
