{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.38 s, sys: 864 ms, total: 8.24 s\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import partial\n",
    "from collections import defaultdict, namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from video699.screen.semantic_segmentation.fastai_detector import *\n",
    "from video699.screen.semantic_segmentation.common import *\n",
    "from video699.screen.semantic_segmentation.postprocessing import *\n",
    "from video699.screen.semantic_segmentation.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor = [2, 8]\n",
    "frozen_epochs = [2, 5, 6]\n",
    "unfrozen_epochs = [3, 4, 7]\n",
    "base_lower_bound = [5, 7, 10, 15]\n",
    "erosion_dilation_kernel_size = [20, 50, 80, 150]\n",
    "ratio_split_lower_bound = [0.3, 0.4, 0.5, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(product(resize_factor, frozen_epochs, unfrozen_epochs))\n",
    "train_names = ['resize_factor', 'frozen_epochs', 'unfrozen_epochs']\n",
    "\n",
    "post_processing = list(product(base_lower_bound, erosion_dilation_kernel_size, ratio_split_lower_bound))\n",
    "post_processing_names = ['base_lower_bound', 'erosion_dilation_kernel_size', 'ratio_split_lower_bound']\n",
    "\n",
    "all_lectures = [video.filename for video in ALL_VIDEOS]\n",
    "all_frames = [frame for video in ALL_VIDEOS for frame in video]\n",
    "all_frames_grouped_by_videos = {video.filename: [frame for frame in video] for video in ALL_VIDEOS}\n",
    "\n",
    "detector = FastAIScreenDetector()\n",
    "actual_detector = AnnotatedSampledVideoScreenDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_by(name, used):\n",
    "    return any([lecture in str(name) for lecture in used]) and 'frame' in str(name)\n",
    "\n",
    "def split_by(name, validation):\n",
    "    return any([lecture in str(name) for lecture in validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(lectures, train_names, post_processing_names, default_filtered_by, default_split_by):\n",
    "    def make_splits(lectures):\n",
    "        Split = namedtuple('Split', ['train', 'valid'])\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "        splits = {}\n",
    "        for j, split in enumerate(kf.split(lectures)):    \n",
    "            train_lectures = [lectures[index] for index in split[0]]\n",
    "            valid_lectures = [lectures[index] for index in split[1]]\n",
    "            splits[j] = Split(train=train_lectures, valid=valid_lectures)\n",
    "        return splits\n",
    "\n",
    "    splits = make_splits(all_lectures)\n",
    "    df_all = pd.DataFrame(columns=train_names + post_processing_names + ['iou', 'wrong_count', 'kfold_split'])\n",
    "\n",
    "    for train_values in tqdm(train):\n",
    "        resize_factor, frozen_epochs, unfrozen_epochs = train_values\n",
    "        CONFIGURATION['resize_factor'] = str(resize_factor)\n",
    "        CONFIGURATION['frozen_epochs'] = str(frozen_epochs)\n",
    "        CONFIGURATION['unfrozen_epochs'] = str(unfrozen_epochs)\n",
    "\n",
    "        for j in splits.keys():\n",
    "            filtered_by = partial(default_filtered_by, used=splits[j].train + splits[j].valid)\n",
    "            split_by = partial(default_split_by, validation=splits[j].valid)\n",
    "\n",
    "            detector = FastAIScreenDetector(filtered_by=filtered_by, valid_func=split_by)\n",
    "            detector.train()\n",
    "\n",
    "            valid_frames = [frame for frame in all_frames if split_by(frame.pathname)]\n",
    "            actuals = [actual_detector.detect(frame) for frame in valid_frames]\n",
    "            sem_preds = detector.semantic_segmentation_batch(valid_frames)\n",
    "\n",
    "            for post_processing_values in post_processing:    \n",
    "                preds = detector.post_processing_batch(sem_preds, valid_frames, **dict(zip(post_processing_names, post_processing_values)))\n",
    "                wrong_count, ious, _ = evaluate(actuals, preds)\n",
    "\n",
    "                iou_score = np.nanmean(ious)\n",
    "                wrong_count = len(wrong_count)\n",
    "                df_all.loc[len(df_all)] = train_values + post_processing_values + (iou_score, wrong_count, j)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_params(best_params):\n",
    "    converted_params = []\n",
    "    for i, par in enumerate(best_params):\n",
    "        if par.is_integer():\n",
    "            converted_params.append(int(par))\n",
    "        elif isinstance(par, np.int64) or isinstance(par, np.float64):\n",
    "            converted_params.append(par.item())\n",
    "        else:\n",
    "            converted_params.append(par)\n",
    "    best_params = tuple(converted_params)\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture-wise 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:28<00:00, 28.77s/it]\u001b[A\n",
      "1it [00:36, 36.63s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:29<00:00, 29.53s/it]\u001b[A\n",
      "2it [01:14, 36.99s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:36<00:00, 36.15s/it]\u001b[A\n",
      "3it [01:57, 38.90s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:32<00:00, 32.14s/it]\u001b[A\n",
      "4it [02:36, 38.95s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Split No. 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:34<00:00, 34.68s/it]\u001b[A\n",
      "5it [03:18, 39.61s/it]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "df_best_models = pd.DataFrame(columns=train_names + post_processing_names + ['iou', 'wrong_count'])\n",
    "\n",
    "for i, split in tqdm(enumerate(kf.split(all_lectures))):\n",
    "    print(f\"###################### Split No. {i}\")\n",
    "    other_lectures = [all_lectures[index] for index in split[0]]\n",
    "    test_lectures = [all_lectures[index] for index in split[1]]\n",
    "    \n",
    "    # Model selection\n",
    "    df_all = model_selection(other_lectures, train_names, post_processing_names, filtered_by, split_by)    \n",
    "    df_all['wrong_count'] = df_all['wrong_count'].astype(int)\n",
    "    best_params = df_all.groupby(train_names + post_processing_names).mean().sort_values(by=['wrong_count', 'iou']).iloc[0].name\n",
    "    best_params = convert_params(best_params)\n",
    "    best_params = dict(zip(train_names + post_processing_names, best_params))\n",
    "    test_filtered_by = partial(filtered_by, used=all_lectures)\n",
    "    test_split_by = partial(split_by, validation=test_lectures)\n",
    "    \n",
    "    \n",
    "    best_detector = FastAIScreenDetector(filtered_by=test_filtered_by, valid_func=test_split_by)\n",
    "    best_detector.train(**best_params)\n",
    "    \n",
    "    test_frames = [frame for frame in all_frames if test_split_by(frame.pathname)]\n",
    "    actuals = [actual_detector.detect(frame) for frame in test_frames]\n",
    "    preds = [best_detector.detect(frame) for frame in test_frames]\n",
    "    \n",
    "    wrong_count, ious, _ = evaluate(actuals, preds)\n",
    "    iou_score = np.nanmean(ious)\n",
    "    wrong_count = len(wrong_count)\n",
    "    df_best_models.loc[len(df_best_models)] = tuple(best_params.values()) + (iou_score, wrong_count)\n",
    "    df_best_models.to_csv('cross_validation_results_frame_wise.csv', index=False)\n",
    "    \n",
    "df_best_models.to_csv('cross_validation_results_frame_wise.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
